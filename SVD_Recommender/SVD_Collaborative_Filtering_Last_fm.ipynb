{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbVcNSXtdFr5hcFUCVX41p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Recommender-Systems/blob/main/SVD_Recommender/SVD_Collaborative_Filtering_Last_fm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1 align=center><font size = 5> SVD Collaborative Filtering - Last.fm </font></h1>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JYSnttb4rjZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Índice**\n",
        "\n",
        "- 1. Introducción\n",
        "- 2. Carga y Filtrado de Datos\n",
        "- 3. Análisis de Energía Acumulada para SVD\n",
        "- 4. Creación del Modelo SVD\n",
        "- 5. Generación de Recomendaciones\n",
        "- 6. Validación\n",
        "- 7. Conclusiones\n"
      ],
      "metadata": {
        "id": "ydzx-jpRrnqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introducción\n",
        "\n",
        "Este laboratorio aplica SVD con filtrado \"long tail\" a los datos de interacciones usuario-artista en Last.fm. Exploraremos la energía acumulada para determinar el número adecuado de factores y evaluaremos el modelo ocultando el 20% de los ítems por usuario para probar la capacidad predictiva del modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "unJidY4XsOLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos las librerías necesarias."
      ],
      "metadata": {
        "id": "7f-q2jwBsX49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHzwCYqVreu1"
      },
      "outputs": [],
      "source": [
        "# Instalar Surprise\n",
        "!pip install scikit-surprise\n",
        "\n",
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.accuracy import rmse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Carga y Filtrado de Datos"
      ],
      "metadata": {
        "id": "yytiu2qUseg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el dataset y aplicamos un filtro \"long tail\" para mejorar la calidad del análisis, manteniendo solo los artistas con al menos 50 escuchas. Este enfoque reduce el impacto de artistas menos populares y permite centrarse en recomendaciones más relevantes.\n",
        "\n"
      ],
      "metadata": {
        "id": "G3bUk65msjm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Sube tu archivo kaggle.json aquí\n",
        "\n",
        "# Crear la carpeta .kaggle y mover el archivo\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "PF75QXFZspHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d japarra27/lastfm-dataset\n",
        "!unzip lastfm-dataset.zip\n"
      ],
      "metadata": {
        "id": "R9R-hCIJsqyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset\n",
        "data = pd.read_parquet(\"lastfm_union.parquet\")[:1_000_000]"
      ],
      "metadata": {
        "id": "BXvRIteAtQjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar las escuchas por artista\n",
        "artist_listen_counts = data.groupby('artist_name').size().sort_values(ascending=False)\n",
        "\n",
        "# Visualizar distribución long tail\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(artist_listen_counts)), artist_listen_counts, color='lightblue')\n",
        "plt.title('Distribución del Número de Escuchas por Artista (Long Tail)')\n",
        "plt.xlabel('Artistas ordenados por popularidad')\n",
        "plt.ylabel('Número de escuchas')\n",
        "plt.ylim(1, 4000)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WnpfGaTYtoUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar artistas con al menos 50 escuchas\n",
        "min_listens_per_artist = 50\n",
        "popular_artists = artist_listen_counts[artist_listen_counts >= min_listens_per_artist].index\n",
        "data_filtered = data[data['artist_name'].isin(popular_artists)]\n",
        "\n",
        "# Crear la matriz usuario-artista con el recuento de escuchas\n",
        "user_artist_matrix = data_filtered.groupby(['user_id', 'artist_name']).size().unstack(fill_value=0)\n"
      ],
      "metadata": {
        "id": "pYB2EkMbtXQU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_artist_matrix.head()"
      ],
      "metadata": {
        "id": "pcLfI5-tt7Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Análisis de Energía Acumulada para SVD\n"
      ],
      "metadata": {
        "id": "DJo8ZbBxu2ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para determinar el número óptimo de factores, usamos SVD sobre la matriz usuario-artista y calculamos la energía acumulada. El objetivo es cubrir al menos el 90% de la variabilidad para lograr una buena representación sin perder demasiada información."
      ],
      "metadata": {
        "id": "6j59AV88u7EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convertir la matriz usuario-artista a formato sparse matrix\n",
        "user_artist_matrix_sparse = csr_matrix(user_artist_matrix, dtype=np.float32)\n",
        "\n",
        "# Realizar la descomposición SVD\n",
        "U, sigma, Vt = svds(user_artist_matrix_sparse, k = min(user_artist_matrix_sparse.shape) - 1)\n",
        "sigma = np.flip(np.sort(sigma))  # Ordenar valores singulares de mayor a menor\n"
      ],
      "metadata": {
        "id": "e582i4JAu6Zc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calcular la energía acumulada\n",
        "explained_variance_ratio = sigma**2 / np.sum(sigma**2)\n",
        "explained_variance_cumsum = np.cumsum(explained_variance_ratio)\n"
      ],
      "metadata": {
        "id": "y24aTi8_u_FG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la energía acumulada\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(explained_variance_cumsum) + 1), explained_variance_cumsum, marker='o', linestyle='--')\n",
        "plt.title('Energía Acumulada por Número de Factores')\n",
        "plt.xlabel('Número de Factores')\n",
        "plt.ylabel('Energía Acumulada')\n",
        "plt.axhline(y=0.9, color='r', linestyle='--')  # Línea en 80% de energía\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Gudnw8NfvAsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinar el número mínimo de factores que explican el 90% de la varianza\n",
        "num_factors = np.argmax(explained_variance_cumsum >= 0.9) + 1\n",
        "print(f\"Número de factores necesarios para cubrir el 80% de la energía: {num_factors}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcct-96FvB2j",
        "outputId": "6f3c9e7f-9bab-4d1e-ca5e-e7448b79327a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de factores necesarios para cubrir el 80% de la energía: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. SVD con enmascaramiento del 20% de Ítems\n"
      ],
      "metadata": {
        "id": "4xQgOhCEwBkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar el modelo, dividimos los datos en conjuntos de entrenamiento y prueba, ocultando el 20% de las interacciones de cada usuario. Esto permite evaluar la capacidad predictiva del modelo en datos no vistos.\n",
        "\n"
      ],
      "metadata": {
        "id": "0rBO_xB3wHGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filtered_grouped = data_filtered.groupby(['user_id', 'artist_name']).size().reset_index(name='listens')\n",
        "data_filtered_grouped.head()"
      ],
      "metadata": {
        "id": "q2YWDDi4zxmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_scaled = data_filtered_grouped\n",
        "trainset_scaled['listens'] = data_filtered_grouped.listens/np.percentile(data_filtered_grouped['listens'], 95)"
      ],
      "metadata": {
        "id": "6eM1WMrc4hBQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Ocultar el 20% de las escuchas por usuario en el conjunto de prueba\n",
        "trainset, testset = train_test_split(data_filtered_grouped, test_size = 0.2, stratify = data_filtered_grouped.user_id)\n"
      ],
      "metadata": {
        "id": "wQFthmR2wlBB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos los conjuntos de entrenamiento y prueba divididos, configuraremos el conjunto de datos en el formato requerido por Surprise. Esto implica cargar los datos con un rango de escucha adecuado para Surprise y construir los objetos trainset y testset."
      ],
      "metadata": {
        "id": "G9y-pjCn1cVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir el rango de puntuaciones con base en el máximo número de escuchas\n",
        "\n",
        "max_listens = trainset['listens'].max()\n",
        "reader = Reader(rating_scale=(0, max_listens))\n",
        "\n",
        "# Cargar el conjunto de entrenamiento en formato Surprise\n",
        "trainset_s = Dataset.load_from_df(trainset[['user_id', 'artist_name', 'listens']], reader).build_full_trainset()\n",
        "\n",
        "# Preparar el conjunto de prueba en formato de lista de tuplas (user_id, artist_name, listens)\n",
        "testset_s = list(testset[['user_id', 'artist_name', 'listens']].itertuples(index=False, name=None))\n"
      ],
      "metadata": {
        "id": "gOPE_HM5wI-i"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Entrenamiento del Modelo SVD\n",
        "\n",
        "Entrenamos el modelo SVD utilizando el conjunto de entrenamiento. Para la cantidad de factores latentes (n_factors), utilizamos el valor obtenido previamente en el análisis de energía acumulada."
      ],
      "metadata": {
        "id": "rnwuXc7X1g6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y entrenar el modelo SVD con el número de factores seleccionado\n",
        "svd_model = SVD(n_factors=num_factors)\n",
        "svd_model.fit(trainset_s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqwCktLJwjdu",
        "outputId": "2edd18d4-ec23-430c-9f47-7a18a427e23f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7842c4e69690>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Generación de Recomendaciones\n"
      ],
      "metadata": {
        "id": "SgRfmmyM1oJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el modelo entrenado para generar recomendaciones para cada usuario. Para cada usuario, se seleccionarán canciones no escuchadas para hacer predicciones de recomendación."
      ],
      "metadata": {
        "id": "xuUJFv4q1rXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset.head()"
      ],
      "metadata": {
        "id": "nIoWsrXX4KTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que aplica `predict` del modelo a cada fila\n",
        "def get_predictions(row):\n",
        "    prediccion = svd_model.predict(row['user_id'], row['artist_name']).est\n",
        "    return prediccion\n"
      ],
      "metadata": {
        "id": "bUVLZCsl4Slo"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset['listens_reconstruida'] = trainset.apply(get_predictions, axis=1)\n",
        "trainset.head()"
      ],
      "metadata": {
        "id": "dkbP5Uw53VIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo del RMSE**\n",
        "\n",
        "Evaluamos la precisión del modelo usando el RMSE, calculando la diferencia promedio entre las listens y listens_reconstruida."
      ],
      "metadata": {
        "id": "qMZxZiNq8CH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el RMSE entre listens y listens_reconstruida\n",
        "rmse = np.sqrt(((trainset['listens'] - trainset['listens_reconstruida']) ** 2).mean())\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "GDQUZEFx6BTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset['listens_reconstruida'] = testset.apply(get_predictions, axis=1)\n",
        "testset.head()"
      ],
      "metadata": {
        "id": "CUONFhvk6NZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el RMSE entre listens y listens_reconstruida\n",
        "rmse = np.sqrt(((testset['listens'] - testset['listens_reconstruida']) ** 2).mean())\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "l1VI1yWI6Vvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo del Hit Rate**\n",
        "\n",
        "Para evaluar las predicciones de escucha/no escucha, usamos un umbral de 0.2. Si listens o listens_reconstruida son mayores a 0.2, los asignamos a 1 (escuchado), de lo contrario a 0 (no escuchado), y calculamos el porcentaje de aciertos (Hit Rate)."
      ],
      "metadata": {
        "id": "UR7tUc-58Gnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las versiones binarizadas de listens y listens_reconstruida con el umbral de 0.2\n",
        "testset['listens_bin'] = (testset['listens'] >= 0.2).astype(int)\n",
        "testset['listens_reconstruida_bin'] = (testset['listens_reconstruida'] >= 0.2).astype(int)\n",
        "\n",
        "# Calcular el Hit Rate: la proporción de coincidencias entre listens_bin y listens_reconstruida_bin\n",
        "hit_rate = (testset['listens_bin'] == testset['listens_reconstruida_bin']).mean()\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"Hit Rate: {hit_rate}\")\n"
      ],
      "metadata": {
        "id": "Hbgzn_7b6dK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el Hit Rate por usuario\n",
        "hit_rate_per_user = testset.groupby('user_id').apply(\n",
        "    lambda df: (df['listens_bin'] == df['listens_reconstruida_bin']).mean()\n",
        ")\n",
        "\n",
        "# Calcular el promedio de Hit Rate de todos los usuarios\n",
        "average_hit_rate = hit_rate_per_user.mean()\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"Hit Rate promedio por usuario: {average_hit_rate}\")"
      ],
      "metadata": {
        "id": "KM2DvQx37ZMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}