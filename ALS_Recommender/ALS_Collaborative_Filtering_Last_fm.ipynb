{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Recommender-Systems/blob/main/ALS_Recommender/ALS_Collaborative_Filtering_Last_fm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM6BxrBQ3mLH"
      },
      "source": [
        "\n",
        "<h1 align=center><font size = 5> ALS Collaborative Filtering - Last.fm </font></h1>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoAUCTsl3s9r"
      },
      "source": [
        "**Índice**\n",
        "\n",
        "- 1. Introducción\n",
        "- 2. Carga y Filtrado de Datos\n",
        "- 3. Creación del Modelo ALS\n",
        "- 4. Generación de Recomendaciones\n",
        "- 5. Validación\n",
        "- 6. Conclusiones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fl2LA2h-Dj3"
      },
      "source": [
        "## 1. Introducción\n",
        "\n",
        "Este laboratorio aplica Mínimos Cuadrados Ordinarios (OLS) con filtrado \"long tail\" a los datos de interacciones usuario-artista en Last.fm. Exploraremos cómo utilizar regresión lineal para predecir las interacciones entre usuarios y artistas. Evaluaremos el modelo ocultando el 20% de los ítems por usuario para probar la capacidad predictiva del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5xwdEsD-oGv"
      },
      "source": [
        "Instalamos las librerías necesarias.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMmEOEeW3kR_"
      },
      "outputs": [],
      "source": [
        "# Instalar librerías necesarias\n",
        "!pip install scikit-surprise kaggle\n",
        "\n",
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from surprise import Dataset, Reader, BaselineOnly\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.accuracy import rmse\n",
        "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lqygrXg-HfE"
      },
      "source": [
        "## 2. Carga y Filtrado de Datos\n",
        "\n",
        "Cargamos el dataset y aplicamos un filtro \"long tail\" para mejorar la calidad del análisis, manteniendo solo los artistas con al menos 50 escuchas. Este enfoque reduce el impacto de artistas menos populares y permite centrarse en recomendaciones más relevantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgpVbhOhEBZi"
      },
      "outputs": [],
      "source": [
        "# Descargar el dataset de Last.fm desde Kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()  # Sube tu archivo kaggle.json aquí\n",
        "\n",
        "# Configurar Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Descargar y descomprimir el dataset de Last.fm\n",
        "!kaggle datasets download -d japarra27/lastfm-dataset\n",
        "!unzip lastfm-dataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7eMEuFfZEKr1"
      },
      "outputs": [],
      "source": [
        "# Cargar el dataset\n",
        "data = pd.read_parquet(\"lastfm_union.parquet\")[:10_000_000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeuPHQpYS-3U"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoRQeQ20Ffoq"
      },
      "source": [
        "**Filtrado \"long tail\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HlijNVFENxg"
      },
      "outputs": [],
      "source": [
        "# Contar las escuchas por artista\n",
        "artist_listen_counts = data.groupby('artist_name').size().sort_values(ascending=False)\n",
        "\n",
        "# Visualizar distribución long tail\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(artist_listen_counts)), artist_listen_counts, color='lightblue')\n",
        "plt.title('Distribución del Número de Escuchas por Artista (Long Tail)')\n",
        "plt.xlabel('Artistas ordenados por popularidad')\n",
        "plt.ylabel('Número de escuchas')\n",
        "plt.ylim(1, 4000)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKx9JayQVC8H"
      },
      "outputs": [],
      "source": [
        "artist_listen_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "xol-L6HtEQuo"
      },
      "outputs": [],
      "source": [
        "# Filtrar artistas con al menos 100 escuchas\n",
        "min_listens_per_artist = 100\n",
        "popular_artists = artist_listen_counts[artist_listen_counts >= min_listens_per_artist].index\n",
        "data_filtered = data[data['artist_name'].isin(popular_artists)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhL3kPdAVYnz"
      },
      "outputs": [],
      "source": [
        "# Filtrar usuarios con al menos 100 escuchas\n",
        "users_listen_counts = data_filtered.groupby('user_id').size().sort_values(ascending=False)\n",
        "users_listen_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KnrN4PRsVjxG"
      },
      "outputs": [],
      "source": [
        "min_listens_per_user = 100\n",
        "popular_users = users_listen_counts[users_listen_counts >= min_listens_per_user].index\n",
        "data_filtered = data_filtered[data_filtered['user_id'].isin(popular_users)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERv1hfqaWmxI"
      },
      "outputs": [],
      "source": [
        "data_filtered.groupby('user_id').size().sort_values(ascending=False).tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW57MblaWzEr"
      },
      "outputs": [],
      "source": [
        "data_filtered.groupby('artist_name').size().sort_values(ascending=False).tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB5I3skLE8x1"
      },
      "source": [
        "## 3. Creación del Modelo ALS\n",
        "\n",
        "Ahora que tenemos los datos filtrados, procederemos a entrenar un modelo de recomendación usando ALS con la biblioteca surprise. En surprise, podemos utilizar el algoritmo BaselineOnly con el método de estimación configurado como ALS.\n",
        "\n",
        "Primero, preparamos los datos en el formato que requiere surprise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADI6xPQQJ1KE"
      },
      "outputs": [],
      "source": [
        "# Crear el DataFrame con el recuento de escuchas\n",
        "user_artist_df = data_filtered.groupby(['user_id', 'artist_name']).size().reset_index(name='listens')\n",
        "user_artist_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFVJH3qCV-7-"
      },
      "outputs": [],
      "source": [
        "np.percentile(user_artist_df['listens'], 95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "kLaZqZPhJ77r"
      },
      "outputs": [],
      "source": [
        "trainset_scaled = user_artist_df\n",
        "trainset_scaled['listens'] = user_artist_df.listens/np.percentile(user_artist_df['listens'], 95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tZ9CAUZFpM_"
      },
      "source": [
        "**División del Conjunto de Datos**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IBLD7HIWTtC"
      },
      "outputs": [],
      "source": [
        "trainset_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "zetFic39E_3l"
      },
      "outputs": [],
      "source": [
        "# Dividir en conjuntos de entrenamiento y prueba estratificando por usuario\n",
        "train_data, test_data = sk_train_test_split(trainset_scaled,\n",
        "    test_size = 0.2,\n",
        "    random_state = 42,\n",
        "    stratify = trainset_scaled['user_id']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JurrlwnQJM4U"
      },
      "source": [
        "## 4. Creación del Modelo ALS\n",
        "\n",
        "Preparamos los datos para surprise y entrenamos el modelo ALS utilizando la clase BaselineOnly con el método als.\n",
        "\n",
        "Preparación de los datos para Surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "q5wQUT2QQdzn"
      },
      "outputs": [],
      "source": [
        "# Definir el rango de puntuaciones basado en los datos de entrenamiento\n",
        "rating_scale = (train_data['listens'].min(), train_data['listens'].max())\n",
        "reader = Reader(rating_scale=rating_scale)\n",
        "\n",
        "# Crear el conjunto de datos de entrenamiento para 'surprise'\n",
        "train_dataset = Dataset.load_from_df(\n",
        "    train_data[['user_id', 'artist_name', 'listens']],\n",
        "    reader\n",
        ")\n",
        "trainset = train_dataset.build_full_trainset()\n",
        "\n",
        "# Crear el conjunto de prueba en formato de lista de tuplas\n",
        "testset = list(\n",
        "    test_data[['user_id', 'artist_name', 'listens']].itertuples(index=False, name=None)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc98vKwUQpZQ"
      },
      "source": [
        "Utilizaremos el modelo BaselineOnly de surprise con el método de estimación als para implementar ALS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY1vth4YXqEp",
        "outputId": "7ff3849a-75f3-4f1c-81c9-2f42c839d2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Mejores hiperparámetros: {'bsl_options': {'method': 'als', 'n_epochs': 100, 'reg_u': 15, 'reg_i': 15}}\n"
          ]
        }
      ],
      "source": [
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# Definir el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'bsl_options': {\n",
        "        'method': ['als'],\n",
        "        'n_epochs': [100],\n",
        "        'reg_u': [0, 1, 5, 10, 15],\n",
        "        'reg_i': [0, 1, 5, 10, 15]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Configurar el objeto GridSearchCV\n",
        "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=3)\n",
        "\n",
        "# Ejecutar la búsqueda\n",
        "gs.fit(train_dataset)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = gs.best_params['rmse']\n",
        "print(f\"Mejores hiperparámetros: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "913lgO6cQrIa",
        "outputId": "c0fa663f-d311-4f5b-e5cf-94477972df00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x7a2f07ebe860>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Configuración de los parámetros de ALS\n",
        "bsl_options = {\n",
        "    'method': 'als',\n",
        "    'n_epochs': 1000,\n",
        "    'reg_u': 15,\n",
        "    'reg_i': 15\n",
        "}\n",
        "\n",
        "# Crear y entrenar el modelo ALS\n",
        "als_model = BaselineOnly(bsl_options = bsl_options)\n",
        "als_model.fit(trainset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl39q8hAJQrU",
        "outputId": "61a9f0b0-5971-4ba4-e64c-5770aa56a9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R² en el conjunto de entrenamiento: 0.08873116760890731\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generar predicciones en el conjunto de entrenamiento\n",
        "trainset_predictions = als_model.test(trainset.build_testset())\n",
        "\n",
        "# Extraer las calificaciones reales y predichas\n",
        "y_true_train = [pred.r_ui for pred in trainset_predictions]\n",
        "y_pred_train = [pred.est for pred in trainset_predictions]\n",
        "\n",
        "# Calcular el R² en el conjunto de entrenamiento\n",
        "r2_train = r2_score(y_true_train, y_pred_train)\n",
        "print(f\"R² en el conjunto de entrenamiento: {r2_train}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generación de Recomendaciones\n"
      ],
      "metadata": {
        "id": "XohlYr4hvMru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos el modelo entrenado para predecir las escuchas en el conjunto de prueba.\n",
        "\n"
      ],
      "metadata": {
        "id": "1AAO5x_XvP2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = als_model.test(testset)\n"
      ],
      "metadata": {
        "id": "yZtqY3gqvSg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMLhAsyvuF4DcvuumqJtGGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}