{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpQmQjRmvWIX3K1j6IPQZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Recommender-Systems/blob/main/Autoencoder_Recommender/Content_Based_Recommerders_TF_IDF_BERT_y_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Content Based Recommerders: TF-IDF, BERT y Autoencoders**"
      ],
      "metadata": {
        "id": "8OoonmlclmKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabla de Contenidos\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item31\">Introducción y Configuración Inicial</a>  \n",
        "2. <a href=\"#item32\">Preparación del Entorno y Descarga del Dataset</a>  \n",
        "3. <a href=\"#item34\">Análisis Exploratorio de Datos</a>  \n",
        "4. <a href=\"#item34\">Recomendaciones Basadas en Contenido con TF-IDF</a>\n",
        "5. <a href=\"#item34\">Recomendaciones Basadas en Contenido con BERT</a>\n",
        "6. <a href=\"#item34\">Recomendaciones Basadas en Contenido con Autoencoders</a>\n",
        "7. <a href=\"#item34\">Conclusiones</a>\n"
      ],
      "metadata": {
        "id": "8hLkf37tmVkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Introducción\n",
        "\n",
        "En este laboratorio, exploraremos cómo generar recomendaciones de artículos basadas en contenido utilizando tres métodos distintos:\n",
        "\n",
        "- TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "- BERT (Bidirectional Encoder Representations from Transformers)\n",
        "- Autoencoders (Redes Neuronales para Aprendizaje No Supervisado)\n",
        "\n",
        "Cada método nos permitirá transformar textos en representaciones numéricas que capturan diferentes aspectos de su contenido, lo que nos ayudará a medir similitudes y generar recomendaciones personalizadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "5NOAWLtymzlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivos del laboratorio:**\n",
        "\n",
        "Implementar sistemas de recomendación basados en contenido utilizando TF-IDF, BERT y Autoencoders.\n",
        "Comprender las ventajas y limitaciones de cada enfoque.\n",
        "Visualizar las relaciones entre los artículos mediante reducción de dimensionalidad."
      ],
      "metadata": {
        "id": "o1b3u4ozm_Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparación del Entorno y Descarga del Dataset\n"
      ],
      "metadata": {
        "id": "Dm7DiKBWnCFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos configurando el entorno y descargando el dataset necesario para nuestro análisis.\n",
        "\n",
        "**Instalación de Dependencias**"
      ],
      "metadata": {
        "id": "T6NZot4RnFS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar la API de Kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "# Subir el archivo kaggle.json con las credenciales de Kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # Sube tu archivo kaggle.json aquí\n",
        "\n",
        "# Configurar la API de Kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "qUvnY81DRkTN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descarga y Preparación del Dataset**\n",
        "\n",
        "Descargamos el dataset de artículos de The Guardian desde Kaggle y lo cargamos en un DataFrame de pandas."
      ],
      "metadata": {
        "id": "jzCjccs-nMML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el dataset\n",
        "!kaggle datasets download -d adityakharosekar2/guardian-news-articles\n",
        "\n",
        "# Descomprimir el archivo descargado\n",
        "!unzip guardian-news-articles.zip\n",
        "\n",
        "# Cargar el dataset en un DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('guardian_articles.csv')\n",
        "\n",
        "# Seleccionar las columnas relevantes y las primeras 1000 filas para agilizar el procesamiento\n",
        "data = data[['webTitle', 'bodyContent']].head(1000)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "b4e5JkxaRmtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. Análisis Exploratorio de Datos\n",
        "\n",
        "Antes de proceder, es importante entender el contenido y la estructura de nuestro dataset."
      ],
      "metadata": {
        "id": "GGP6XKq1nU3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verificación de Datos Nulos**"
      ],
      "metadata": {
        "id": "L-F242iFnaae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores nulos\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "Kek6qHtGSLy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que la columna bodyContent puede tener valores nulos, los cuales manejaremos a continuación."
      ],
      "metadata": {
        "id": "AI61_L99nfBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpieza de Datos**"
      ],
      "metadata": {
        "id": "nJzZ_GhZng3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar valores nulos en 'bodyContent' con cadenas vacías\n",
        "data['bodyContent'] = data['bodyContent'].fillna('')\n"
      ],
      "metadata": {
        "id": "Gn4H_Td3nsAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribución de la Longitud de los Artículos**\n",
        "\n",
        "Analizamos la longitud de los artículos para entender la variabilidad en el contenido."
      ],
      "metadata": {
        "id": "w3Az0GEwnueV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir una columna con la longitud de cada artículo\n",
        "data['text_length'] = data['bodyContent'].apply(len)\n",
        "\n",
        "# Visualizar la distribución de la longitud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(data['text_length'], bins=30, edgecolor='black')\n",
        "plt.title('Distribución de la Longitud de los Artículos')\n",
        "plt.xlabel('Longitud del Texto')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2cpPZMhXSbte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Recomendaciones Basadas en Contenido con TF-IDF\n",
        "\n",
        "**¿Qué es TF-IDF?**\n",
        "\n",
        "TF-IDF es una técnica que combina la frecuencia de un término en un documento (TF) con la frecuencia inversa del término en el corpus (IDF) para calcular la importancia relativa de palabras en un documento específico."
      ],
      "metadata": {
        "id": "0c8kCoqln06B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementación de TF-IDF**"
      ],
      "metadata": {
        "id": "8LPcH4WCn5rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Crear una instancia del vectorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Ajustar y transformar los textos\n",
        "tfidf_matrix = vectorizer.fit_transform(data['bodyContent'])\n",
        "\n",
        "print(\"Dimensiones de la matriz TF-IDF:\", tfidf_matrix.shape)\n"
      ],
      "metadata": {
        "id": "IxLKJGi2S1B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz TF-IDF resultante tiene una fila por artículo y una columna por cada término del vocabulario."
      ],
      "metadata": {
        "id": "SU17_-pjn_wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de la Similitud del Coseno**\n",
        "\n",
        "Utilizamos la similitud del coseno para medir qué tan similares son dos artículos en base a sus vectores TF-IDF."
      ],
      "metadata": {
        "id": "Y2ca2WtWoCDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calcular la matriz de similitud\n",
        "similarity_matrix_tfidf = cosine_similarity(tfidf_matrix)\n"
      ],
      "metadata": {
        "id": "7a_bgCyQSs21"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función para Recomendar Artículos**\n",
        "\n",
        "Definimos una función que, dado un índice de artículo, recomiende los artículos más similares."
      ],
      "metadata": {
        "id": "OPi97BcroIqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_articles_tfidf(article_index, similarity_matrix, data, top_n=5):\n",
        "    # Obtener los índices de los artículos más similares\n",
        "    similar_indices = similarity_matrix[article_index].argsort()[-top_n-1:-1][::-1]\n",
        "\n",
        "    # Extraer los títulos de los artículos recomendados\n",
        "    recommended_articles = data.iloc[similar_indices]\n",
        "\n",
        "    print(\"Artículo seleccionado:\")\n",
        "    print(data.iloc[article_index]['webTitle'], \"\\n\")\n",
        "\n",
        "    print(\"Artículos recomendados basados en TF-IDF:\")\n",
        "    for idx, row in recommended_articles.iterrows():\n",
        "        print(\"-\", row['webTitle'])\n"
      ],
      "metadata": {
        "id": "z235_JJXSyJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo de Recomendación**\n",
        "\n",
        "Probamos la función con un artículo específico."
      ],
      "metadata": {
        "id": "lK-Xw4R1oO3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegir un artículo de ejemplo\n",
        "article_index = 10\n",
        "\n",
        "# Generar recomendaciones\n",
        "recommend_articles_tfidf(article_index, similarity_matrix_tfidf, data)\n"
      ],
      "metadata": {
        "id": "8Hf69BhPTz9K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Recomendaciones Basadas en Contenido con BERT\n",
        "\n",
        "**¿Qué es BERT?**\n",
        "\n",
        "BERT es un modelo de lenguaje desarrollado por Google que utiliza transformadores para comprender el contexto bidireccional de las palabras en un texto, generando embeddings contextuales de alta calidad."
      ],
      "metadata": {
        "id": "OIf-YIZMoYmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementación de Embeddings con BERT**"
      ],
      "metadata": {
        "id": "aA-RefOaod5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalación de Sentence Transformers"
      ],
      "metadata": {
        "id": "kpioh0TmogzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "xP66LNPrT3BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generación de Embeddings**\n"
      ],
      "metadata": {
        "id": "BD65M_6_omZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generar embeddings para los textos\n",
        "embeddings = model.encode(data['bodyContent'], show_progress_bar=True)\n",
        "\n",
        "print(\"Dimensiones de los embeddings:\", embeddings.shape)\n"
      ],
      "metadata": {
        "id": "TVv3JgSaT-9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada artículo ahora está representado por un vector de dimensiones fijas que captura su significado semántico."
      ],
      "metadata": {
        "id": "S6Ds8DLNovnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de la Similitud del Coseno**"
      ],
      "metadata": {
        "id": "ipu0tgiToxiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la matriz de similitud\n",
        "similarity_matrix_bert = cosine_similarity(embeddings)\n"
      ],
      "metadata": {
        "id": "f0LI0WUvUTD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función para Recomendar Artículos**\n",
        "\n",
        "Utilizamos una función similar a la anterior, adaptada para los embeddings de BERT."
      ],
      "metadata": {
        "id": "yfrrVvM3o2av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_articles_bert(article_index, similarity_matrix, data, top_n=5):\n",
        "    # Obtener los índices de los artículos más similares\n",
        "    similar_indices = similarity_matrix[article_index].argsort()[-top_n-1:-1][::-1]\n",
        "\n",
        "    # Extraer los títulos de los artículos recomendados\n",
        "    recommended_articles = data.iloc[similar_indices]\n",
        "\n",
        "    print(\"Artículo seleccionado:\")\n",
        "    print(data.iloc[article_index]['webTitle'], \"\\n\")\n",
        "\n",
        "    print(\"Artículos recomendados basados en BERT:\")\n",
        "    for idx, row in recommended_articles.iterrows():\n",
        "        print(\"-\", row['webTitle'])\n"
      ],
      "metadata": {
        "id": "d2YDvkCaagFu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo de Recomendación**"
      ],
      "metadata": {
        "id": "QSxM1K_Lo8OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegir un artículo de ejemplo\n",
        "article_index = 10\n",
        "\n",
        "# Generar recomendaciones\n",
        "recommend_articles_bert(article_index, similarity_matrix_bert, data)\n"
      ],
      "metadata": {
        "id": "E2BpRKYhUV93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Recomendaciones Basadas en Contenido con Autoencoders\n",
        "\n",
        "**¿Qué es un Autoencoder?**\n",
        "Un autoencoder es una red neuronal que aprende a copiar su entrada a su salida. Consta de dos partes:\n",
        "\n",
        "**Encoder:** Comprime la entrada en una representación latente de menor dimensión.\n",
        "**Decoder:** Reconstruye la entrada original a partir de la representación latente.\n",
        "Al entrenar el autoencoder, la red aprende a captar las características más importantes de los datos."
      ],
      "metadata": {
        "id": "Bk8WI6Z9pCK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocesamiento Avanzado de Textos**\n"
      ],
      "metadata": {
        "id": "EvSM7XuA9E3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminación de Stopwords y Tokenización en Trigramas**"
      ],
      "metadata": {
        "id": "f8h_wTsa9ICh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenizar el texto\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Eliminar stopwords y palabras no alfanuméricas\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Aplicar el preprocesamiento\n",
        "data['processed_text'] = data['bodyContent'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "xOsqfPmi9Kwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construcción del Vocabulario con Trigramas**"
      ],
      "metadata": {
        "id": "1YaupB2d9VLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Crear una instancia del vectorizador de conteo\n",
        "vectorizer = CountVectorizer(ngram_range=(3,3), max_features=5000)\n",
        "\n",
        "# Ajustar y transformar los textos procesados\n",
        "vocab_matrix = vectorizer.fit_transform(data['processed_text'])\n",
        "\n",
        "print(\"Dimensiones de la matriz de vocabulario:\", vocab_matrix.shape)\n"
      ],
      "metadata": {
        "id": "Dgh-Nofn9Z-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construcción y Entrenamiento del Autoencoder**\n"
      ],
      "metadata": {
        "id": "i0HKDeBf9bsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición del Modelo"
      ],
      "metadata": {
        "id": "AFlsiTJG9ecE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "input_dim = vocab_matrix.shape[1]\n",
        "encoding_dim = 100  # Dimensión de la representación latente\n",
        "\n",
        "# Capa de entrada\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Codificación\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "\n",
        "# Decodificación\n",
        "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "# Modelo autoencoder\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
        "\n",
        "# Modelo encoder (para obtener las representaciones latentes)\n",
        "encoder = Model(inputs=input_layer, outputs=encoded)\n"
      ],
      "metadata": {
        "id": "XcZ04pIs9g0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compilación y Entrenamiento**"
      ],
      "metadata": {
        "id": "Nn2gS0HR9YIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Convertir la matriz de vocabulario a array denso\n",
        "vocab_matrix_dense = vocab_matrix.toarray()\n",
        "\n",
        "# Entrenar el modelo\n",
        "autoencoder.fit(vocab_matrix_dense, vocab_matrix_dense,\n",
        "                epochs=20,\n",
        "                batch_size=32,\n",
        "                shuffle=True)\n"
      ],
      "metadata": {
        "id": "EuEr0q0I90so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtención de Representaciones Latentes**"
      ],
      "metadata": {
        "id": "DPbD-F3693C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las representaciones latentes\n",
        "latent_representations = encoder.predict(vocab_matrix_dense)\n",
        "\n",
        "print(\"Dimensiones de las representaciones latentes:\", latent_representations.shape)\n"
      ],
      "metadata": {
        "id": "fYJ54UZX96DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cálculo de la Similitud del Coseno**"
      ],
      "metadata": {
        "id": "0F01FDS597gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la matriz de similitud\n",
        "similarity_matrix_autoencoder = cosine_similarity(latent_representations)\n"
      ],
      "metadata": {
        "id": "P3u7pdHq9-J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función para Recomendar Artículos**"
      ],
      "metadata": {
        "id": "dpmBIj8Q-BJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_articles_autoencoder(article_index, similarity_matrix, data, top_n=5):\n",
        "    # Obtener los índices de los artículos más similares\n",
        "    similar_indices = similarity_matrix[article_index].argsort()[-top_n-1:-1][::-1]\n",
        "\n",
        "    # Extraer los títulos de los artículos recomendados\n",
        "    recommended_articles = data.iloc[similar_indices]\n",
        "\n",
        "    print(\"Artículo seleccionado:\")\n",
        "    print(data.iloc[article_index]['webTitle'], \"\\n\")\n",
        "\n",
        "    print(\"Artículos recomendados basados en Autoencoder:\")\n",
        "    for idx, row in recommended_articles.iterrows():\n",
        "        print(\"-\", row['webTitle'])\n"
      ],
      "metadata": {
        "id": "rj65YUr0-D5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo de Recomendación**"
      ],
      "metadata": {
        "id": "7XWzeJ08-GDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegir un artículo de ejemplo\n",
        "article_index = 10\n",
        "\n",
        "# Generar recomendaciones\n",
        "recommend_articles_autoencoder(article_index, similarity_matrix_autoencoder, data)\n"
      ],
      "metadata": {
        "id": "KLTdMULl-IwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualización de Clusters con t-SNE\n",
        "\n",
        "**¿Qué es t-SNE?**\n",
        "t-SNE es una técnica para reducir la dimensionalidad de datos de alta dimensión, permitiendo visualizar patrones y clusters en un espacio de dos o tres dimensiones."
      ],
      "metadata": {
        "id": "KIQ9zdpA-MNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementación de t-SNE**\n",
        "\n",
        "Aplicando t-SNE a las Representaciones Latentes"
      ],
      "metadata": {
        "id": "w6AzNUQO-Qih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "# Reducir la dimensionalidad con t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(latent_representations)\n"
      ],
      "metadata": {
        "id": "YcEj5FoJ-TCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualización**"
      ],
      "metadata": {
        "id": "0kyVbxOH-VZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame con los resultados de t-SNE\n",
        "tsne_df = pd.DataFrame(tsne_results, columns=['Dim1', 'Dim2'])\n",
        "tsne_df['title'] = data['webTitle']\n",
        "\n",
        "# Graficar los resultados\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(tsne_df['Dim1'], tsne_df['Dim2'], alpha=0.7)\n",
        "plt.title('Visualización de Artículos con t-SNE')\n",
        "plt.xlabel('Dimensión 1')\n",
        "plt.ylabel('Dimensión 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a3MMi1GS-X2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar agrupaciones de artículos que son similares según las representaciones aprendidas por el autoencoder."
      ],
      "metadata": {
        "id": "KyS9c-fQ-aER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusiones\n",
        "\n",
        "\n",
        "En este laboratorio, hemos implementado tres enfoques distintos para generar recomendaciones basadas en contenido:\n",
        "\n",
        "**TF-IDF:** Un método sencillo y eficiente que considera la frecuencia de términos. Sin embargo, no captura relaciones semánticas profundas.\n",
        "**BERT:** Proporciona embeddings contextuales que reflejan mejor el significado del texto, mejorando la calidad de las recomendaciones.\n",
        "**Autoencoders:** Aprenden representaciones latentes que pueden captar patrones complejos en los datos, ofreciendo una alternativa poderosa para sistemas de recomendación.\n",
        "\n"
      ],
      "metadata": {
        "id": "6s25mmj7-eXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflexiones finales:**\n",
        "\n",
        "- Calidad de las Recomendaciones: BERT y los Autoencoders suelen proporcionar recomendaciones más precisas que TF-IDF debido a su capacidad para entender el contexto y las relaciones semánticas.\n",
        "\n",
        "- Costo Computacional: TF-IDF es menos costoso computacionalmente en comparación con BERT y los Autoencoders.\n",
        "\n",
        "- Aplicabilidad: La elección del método depende de los recursos disponibles y de la complejidad requerida en las recomendaciones."
      ],
      "metadata": {
        "id": "8WnASf8p-m1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Gracias por completar este laboratorio!"
      ],
      "metadata": {
        "id": "ok_K0FsG-tfq"
      }
    }
  ]
}