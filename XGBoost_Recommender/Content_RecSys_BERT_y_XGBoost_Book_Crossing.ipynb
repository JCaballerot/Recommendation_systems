{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCzm2UaN6FTKG2ceQjeErA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Recommender-Systems/blob/main/XGBoost_Recommender/Content_RecSys_BERT_y_XGBoost_Book_Crossing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/1661575/2726067/684ac0c4c14cb46d1047ccb620b45cac/dataset-cover.jpg?t=2021-10-21-03-18-09\" width=\"800\" height=\"300\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "2yFbptc-h4bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Content RecSys: BERT y XGBoost Book-Crossing**"
      ],
      "metadata": {
        "id": "6j7nVu4kg-RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "## Tabla de Contenidos\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item1\">Introducción</a>  \n",
        "2. <a href=\"#item4\">Descripción del Dataset</a>  \n",
        "3. <a href=\"#item4\">Preprocesamiento de Datos</a>  \n",
        "4. <a href=\"#item4\">Muestreo/Enmascaramiento</a>  \n",
        "5. <a href=\"#item4\">Feature engineering</a>  \n",
        "6. <a href=\"#item4\">Preparación de los Datos para el Modelo</a>  \n",
        "7. <a href=\"#item4\">Entrenamiento del Modelo con XGBoost</a>  \n",
        "8. <a href=\"#item4\">Evaluación del Modelo</a>  \n",
        "9. <a href=\"#item4\">Generación de Recomendaciones</a>  \n",
        "10. <a href=\"#item4\">Conclusiones</a>  \n",
        "\n",
        "</font>\n",
        "</div>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aUw1RvzfhQ1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introducción\n",
        "\n",
        "El dataset de **Book-Crossing** es un recurso rico en información sobre las interacciones de usuarios con libros, capturando calificaciones, títulos, autores y otros datos relevantes. Este laboratorio propone desarrollar un sistema de recomendación basado en **machine learning**, combinando técnicas avanzadas de procesamiento de texto con **BERT** y aprendizaje supervisado mediante **XGBoost**.\n",
        "\n",
        "El objetivo principal es predecir si un usuario disfrutará un libro en particular, basado en sus interacciones pasadas y características tanto del usuario como del libro. Además, se busca generar recomendaciones personalizadas y evaluar métricas como la diversidad global de las recomendaciones.\n",
        "\n",
        "A lo largo del laboratorio, se explorarán diferentes técnicas de ingeniería de características, como el uso de variables cuantitativas, target encoding para variables categóricas, y **embeddings** textuales obtenidos con **BERT**. Finalmente, se entrenará un modelo de **XGBoost**, y se evaluará su desempeño utilizando métricas como el coeficiente de Gini."
      ],
      "metadata": {
        "id": "Rd6n5DqThtkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Descripción del Dataset\n",
        "\n",
        "El dataset de Book-Crossing contiene 3 archivos principales:\n",
        "\n",
        "- **BX-Users.csv:** Información sobre los usuarios.\n",
        "- **BX-Books.csv:** Información sobre los libros.\n",
        "- **BX-Book-Ratings.csv:** Calificaciones dadas por los usuarios a los libros.\n",
        "\n",
        "El dataset puede ser descargado desde: Book-Crossing Dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "h0B39u5LjbSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3.1\"></a>\n",
        "\n",
        "**2.1. BX-Users.csv**\n",
        "\n",
        "Contiene información de los usuarios:\n",
        "\n",
        "- **User-ID:** Identificador único del usuario.\n",
        "- **Location:** Ubicación del usuario.\n",
        "- **Age:** Edad del usuario.\n",
        "\n"
      ],
      "metadata": {
        "id": "viNozbdwj5sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3.2\"></a>\n",
        "\n",
        "**2.2. BX-Books.csv**\n",
        "\n",
        "Contiene información de los libros:\n",
        "\n",
        "- **SBN:** Identificador único del libro.\n",
        "- **Book-Title:** Título del libro.\n",
        "- **Book-Author:** Autor del libro.\n",
        "- **Year-Of-Publication:** Año de publicación.\n",
        "- **Publisher:** Editorial.\n"
      ],
      "metadata": {
        "id": "iXwqVRGOj7V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3.3\"></a>\n",
        "\n",
        "**2.3. BX-Book-Ratings.csv**\n",
        "Contiene las calificaciones de los usuarios:\n",
        "\n",
        "- **User-ID:** Identificador del usuario.\n",
        "- **ISBN:** Identificador del libro.\n",
        "- **Book-Rating:** Calificación dada al libro (0-10).\n"
      ],
      "metadata": {
        "id": "xU5j7ggbj8xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preprocesamiento de Datos\n"
      ],
      "metadata": {
        "id": "Hg8hForFkfBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, cargaremos los datos y realizaremos una limpieza y exploración inicial.\n",
        "\n"
      ],
      "metadata": {
        "id": "IOcS1BH7khhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1. Carga de los Datos**"
      ],
      "metadata": {
        "id": "XW_B8CXnkmkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar los archivos CSV\n",
        "ratings = pd.read_csv(\"BX-Book-Ratings.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n",
        "books = pd.read_csv(\"BX-Books.csv\", sep=\";\", encoding=\"ISO-8859-1\", on_bad_lines=\"skip\", low_memory=False)\n",
        "users = pd.read_csv(\"BX-Users.csv\", sep=\";\", encoding=\"ISO-8859-1\")\n"
      ],
      "metadata": {
        "id": "rAd2-KbXl1QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Exploración y Limpieza**\n",
        "\n",
        "Visualizar las primeras filas de cada dataframe:"
      ],
      "metadata": {
        "id": "3pjdAPKml3C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras filas de ratings\n",
        "print(ratings.head())\n",
        "\n",
        "# Mostrar las primeras filas de books\n",
        "print(books.head())\n",
        "\n",
        "# Mostrar las primeras filas de users\n",
        "print(users.head())\n"
      ],
      "metadata": {
        "id": "StsxWPI5kmC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpieza de Datos**\n",
        "\n",
        "Conversión de tipos de datos.\n",
        "\n",
        "Manejo de valores faltantes."
      ],
      "metadata": {
        "id": "ibOhppYnl9J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir 'Year-Of-Publication' a numérico y manejar errores\n",
        "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
        "books['Year-Of-Publication'].fillna(books['Year-Of-Publication'].median(), inplace=True)\n",
        "books['Year-Of-Publication'] = books['Year-Of-Publication'].astype(int)\n"
      ],
      "metadata": {
        "id": "kd9dOkTTmCaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manejar valores faltantes en 'Book-Author' y 'Publisher'\n",
        "books['Book-Author'].fillna('Unknown', inplace=True)\n",
        "books['Publisher'].fillna('Unknown', inplace=True)\n"
      ],
      "metadata": {
        "id": "gs6G28-3mD3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir 'Age' a numérico y manejar errores\n",
        "users['Age'] = pd.to_numeric(users['Age'], errors='coerce')\n",
        "users['Age'].fillna(users['Age'].median(), inplace=True)\n",
        "users['Age'] = users['Age'].astype(int)"
      ],
      "metadata": {
        "id": "aoWPieojmE4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. División de los Datos\n",
        "\n",
        "Para evaluar el modelo de manera adecuada, separaremos un 10% de las calificaciones de cada usuario para utilizarlas como conjunto de prueba."
      ],
      "metadata": {
        "id": "ndcDbvlZmIUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "# Unir ratings con usuarios y libros\n",
        "data = ratings.merge(users, on='User-ID').merge(books, on='ISBN')\n",
        "\n",
        "# Binarizar el target: 1 si Book-Rating > 5, 0 si <= 5\n",
        "data['target'] = (data['Book-Rating'] > 5).astype(int)\n"
      ],
      "metadata": {
        "id": "s_ejJG2rmNo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar en entrenamiento y prueba por usuario\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(data, groups=data['User-ID']))\n",
        "\n",
        "train_data = data.iloc[train_idx].reset_index(drop=True)\n",
        "test_data = data.iloc[test_idx].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "D-QpGwkVmQ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Ingeniería de Características\n",
        "\n",
        "En esta sección, crearemos nuevas características que ayuden al modelo a predecir con mayor precisión."
      ],
      "metadata": {
        "id": "G3NTPuOCl6Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.1. Variables Cuantitativas**\n",
        "\n",
        "- Edad del usuario (Age).\n",
        "\n",
        "- Antigüedad del libro: Año actual menos el año de publicación."
      ],
      "metadata": {
        "id": "PudN4w2_mZO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "current_year = datetime.now().year\n",
        "\n",
        "# Calcular la antigüedad del libro\n",
        "train_data['Book-Age'] = current_year - train_data['Year-Of-Publication']\n",
        "test_data['Book-Age'] = current_year - test_data['Year-Of-Publication']\n"
      ],
      "metadata": {
        "id": "M5EUYEg5mdOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.2. Target Encoding**\n",
        "\n",
        "Aplicaremos target encoding a las variables categóricas:\n",
        "\n",
        "- Location\n",
        "- Book-Author\n",
        "- Publisher"
      ],
      "metadata": {
        "id": "9aZoEE3Ymf64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import TargetEncoder\n",
        "\n",
        "categorical_features = ['Location', 'Book-Author', 'Publisher']\n",
        "\n",
        "encoder = TargetEncoder(cols=categorical_features)\n",
        "\n",
        "# Ajustar el encoder en los datos de entrenamiento\n",
        "encoder.fit(train_data[categorical_features], train_data['target'])\n",
        "\n",
        "# Transformar las variables categóricas\n",
        "train_encoded = encoder.transform(train_data[categorical_features])\n",
        "test_encoded = encoder.transform(test_data[categorical_features])\n",
        "\n",
        "# Añadir las variables codificadas al dataframe\n",
        "train_data = pd.concat([train_data, train_encoded], axis=1)\n",
        "test_data = pd.concat([test_data, test_encoded], axis=1)\n"
      ],
      "metadata": {
        "id": "KQT4pZlBmteK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.3. Generación de Embeddings con BERT**\n",
        "\n",
        "Utilizaremos BERT para convertir el título del libro en embeddings numéricos que capturen su semántica.\n",
        "\n"
      ],
      "metadata": {
        "id": "Enz7_lwtmwOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalación y Carga de BERT**"
      ],
      "metadata": {
        "id": "yMON78f6m26j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar la biblioteca transformers\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Cargar el tokenizador y el modelo preentrenado\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "id": "tyedF56km5Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para Obtener Embeddings"
      ],
      "metadata": {
        "id": "eRKZBg1-m8dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_embedding(text):\n",
        "    # Tokenización y codificación\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=20)\n",
        "    # Obtener las representaciones del modelo\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Usar el embedding del token [CLS] como representación\n",
        "    embedding = outputs.last_hidden_state[:,0,:].numpy()\n",
        "    return embedding.flatten()\n"
      ],
      "metadata": {
        "id": "QCKKjOixm_ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aplicar la Función a los Datos**\n",
        "\n",
        "Debido a limitaciones computacionales, podemos trabajar con una muestra."
      ],
      "metadata": {
        "id": "pZDS75uInBuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Obtener embeddings para el título del libro en el conjunto de entrenamiento\n",
        "train_embeddings = np.vstack(train_data['Book-Title'].apply(get_bert_embedding))\n",
        "\n",
        "# Obtener embeddings para el conjunto de prueba\n",
        "test_embeddings = np.vstack(test_data['Book-Title'].apply(get_bert_embedding))\n"
      ],
      "metadata": {
        "id": "Dzkf8onInEZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.4. One-Hot Encoding basado en Productos Calificados**\n",
        "\n",
        "Crearemos características que indiquen si el usuario ya ha calificado el libro y el puntaje que le dio previamente."
      ],
      "metadata": {
        "id": "L0IVVkgVnGcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crear un Diccionario de Calificaciones por Usuario**"
      ],
      "metadata": {
        "id": "3pL_f7hVnl9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario de libros calificados por usuario\n",
        "user_rated_books = train_data.groupby('User-ID')['ISBN'].apply(set).to_dict()\n",
        "\n",
        "# Función para verificar si el usuario ya calificó el libro\n",
        "def has_rated(user_id, isbn):\n",
        "    return int(isbn in user_rated_books.get(user_id, set()))\n"
      ],
      "metadata": {
        "id": "NQykpO1Vnoln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aplicar la Función a los Datos**"
      ],
      "metadata": {
        "id": "fx--c5RQnqLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir el flag de 'ya lo calificó'\n",
        "train_data['Already_Rated'] = train_data.apply(lambda x: has_rated(x['User-ID'], x['ISBN']), axis=1)\n",
        "test_data['Already_Rated'] = test_data.apply(lambda x: has_rated(x['User-ID'], x['ISBN']), axis=1)\n"
      ],
      "metadata": {
        "id": "SVeM5cV1ntPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Añadir el Puntaje Dado Anteriormente**"
      ],
      "metadata": {
        "id": "_9BRXdpunvaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario de calificaciones previas\n",
        "user_book_rating = train_data.set_index(['User-ID', 'ISBN'])['Book-Rating'].to_dict()\n",
        "\n",
        "# Función para obtener el puntaje anterior\n",
        "def previous_rating(user_id, isbn):\n",
        "    return user_book_rating.get((user_id, isbn), 0)  # 0 si no existe\n",
        "\n",
        "# Añadir la calificación previa\n",
        "train_data['Previous_Rating'] = train_data.apply(lambda x: previous_rating(x['User-ID'], x['ISBN']), axis=1)\n",
        "test_data['Previous_Rating'] = test_data.apply(lambda x: previous_rating(x['User-ID'], x['ISBN']), axis=1)\n"
      ],
      "metadata": {
        "id": "A8D-DFsEnyVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Preparación de los Datos para el Modelo\n",
        "\n",
        "Seleccionaremos las características y prepararemos los conjuntos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "KfWBHP2-n5bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables cuantitativas\n",
        "quant_features = ['Age', 'Book-Age', 'Already_Rated', 'Previous_Rating']\n",
        "\n",
        "# Variables de target encoding\n",
        "encoded_features = encoder.get_feature_names()\n",
        "\n",
        "# Combinar todas las características\n",
        "X_train = np.hstack([train_data[quant_features + encoded_features].values, train_embeddings])\n",
        "X_test = np.hstack([test_data[quant_features + encoded_features].values, test_embeddings])\n",
        "\n",
        "# Variables objetivo\n",
        "y_train = train_data['target'].values\n",
        "y_test = test_data['target'].values\n"
      ],
      "metadata": {
        "id": "-HB85yaNn9FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Entrenamiento del Modelo con XGBoost\n",
        "\n",
        "Entrenaremos un modelo de clasificación utilizando XGBoost."
      ],
      "metadata": {
        "id": "bb8t1LX6n_EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar XGBoost\n",
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# Crear el modelo XGBoost\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "y9E2YG-poBzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Evaluación del Modelo\n",
        "\n",
        "Evaluaremos el rendimiento del modelo utilizando el coeficiente de Gini."
      ],
      "metadata": {
        "id": "3HSy5FvPoFRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función para Calcular el Gini**"
      ],
      "metadata": {
        "id": "5yZbvyjpoKEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def gini_coefficient(y_true, y_score):\n",
        "    # Calcular el AUC-ROC\n",
        "    auc = roc_auc_score(y_true, y_score)\n",
        "    return 2 * auc - 1\n"
      ],
      "metadata": {
        "id": "SE7693HIoNSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar el Modelo"
      ],
      "metadata": {
        "id": "PKdiwThHoPDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir probabilidades en el conjunto de prueba\n",
        "y_probs = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Calcular el Gini\n",
        "gini = gini_coefficient(y_test, y_probs)\n",
        "print(f'Coeficiente de Gini en el conjunto de prueba: {gini:.4f}')\n"
      ],
      "metadata": {
        "id": "RhAy2B6MoRQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Generación de Recomendaciones\n",
        "\n",
        "Generaremos recomendaciones personalizadas para los usuarios y calcularemos la diversidad global."
      ],
      "metadata": {
        "id": "SwKa3Gr7oTmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.1. Predicción para Libros No Calificados**\n",
        "\n",
        "Para cada usuario, recomendamos los 10 libros con mayor probabilidad de gustarle."
      ],
      "metadata": {
        "id": "O6q0GbvsoYQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Obtener todos los ISBN únicos\n",
        "all_isbns = books['ISBN'].unique()\n",
        "\n",
        "# Diccionario de libros ya calificados por usuario\n",
        "user_rated_books_all = data.groupby('User-ID')['ISBN'].apply(set).to_dict()\n",
        "\n",
        "recommendations = {}\n",
        "\n",
        "for user_id in tqdm(test_data['User-ID'].unique()):\n",
        "    # Libros no calificados por el usuario\n",
        "    unrated_books = set(all_isbns) - user_rated_books_all.get(user_id, set())\n",
        "    # Crear un dataframe temporal\n",
        "    temp_df = pd.DataFrame({'User-ID': user_id, 'ISBN': list(unrated_books)})\n",
        "    # Unir con información de usuarios y libros\n",
        "    temp_df = temp_df.merge(users, on='User-ID').merge(books, on='ISBN', how='left')\n",
        "    # Manejar valores faltantes\n",
        "    temp_df['Age'].fillna(users['Age'].median(), inplace=True)\n",
        "    temp_df['Year-Of-Publication'].fillna(books['Year-Of-Publication'].median(), inplace=True)\n",
        "    temp_df['Book-Author'].fillna('Unknown', inplace=True)\n",
        "    temp_df['Publisher'].fillna('Unknown', inplace=True)\n",
        "    temp_df['Book-Title'].fillna('', inplace=True)\n",
        "    # Calcular 'Book-Age'\n",
        "    temp_df['Year-Of-Publication'] = temp_df['Year-Of-Publication'].astype(int)\n",
        "    temp_df['Book-Age'] = current_year - temp_df['Year-Of-Publication']\n",
        "    # Target Encoding\n",
        "    temp_encoded = encoder.transform(temp_df[categorical_features])\n",
        "    temp_df = pd.concat([temp_df, temp_encoded], axis=1)\n",
        "    # Embeddings con BERT\n",
        "    temp_embeddings = np.vstack(temp_df['Book-Title'].apply(get_bert_embedding))\n",
        "    # Variables cuantitativas\n",
        "    temp_df['Already_Rated'] = 0  # No lo han calificado aún\n",
        "    temp_df['Previous_Rating'] = 0  # No hay calificación previa\n",
        "    temp_quant_features = temp_df[quant_features + encoded_features].values\n",
        "    X_temp = np.hstack([temp_quant_features, temp_embeddings])\n",
        "    # Predecir probabilidades\n",
        "    temp_probs = model.predict_proba(X_temp)[:,1]\n",
        "    temp_df['probability'] = temp_probs\n",
        "    # Obtener los 10 libros con mayor probabilidad\n",
        "    top_10 = temp_df.nlargest(10, 'probability')['ISBN'].tolist()\n",
        "    recommendations[user_id] = top_10\n"
      ],
      "metadata": {
        "id": "OnwOtsM7obyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.2. Cálculo de la Diversidad Global**\n",
        "\n",
        "Calculamos la proporción de libros únicos recomendados respecto al total del catálogo."
      ],
      "metadata": {
        "id": "uAWt_dOXoevh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de libros recomendados\n",
        "recommended_books = set()\n",
        "\n",
        "for recs in recommendations.values():\n",
        "    recommended_books.update(recs)\n",
        "\n",
        "diversity = len(recommended_books) / len(all_isbns)\n",
        "print(f'Diversidad Global de Recomendaciones: {diversity:.4f}')\n"
      ],
      "metadata": {
        "id": "LsLRqr1ZoiKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Conclusiones\n",
        "\n",
        "En este laboratorio, hemos implementado un sistema de recomendación que combina técnicas avanzadas de procesamiento de lenguaje natural y aprendizaje automático:\n",
        "\n",
        "**BERT** nos permitió convertir títulos de libros en representaciones numéricas que capturan su significado semántico.\n",
        "\n",
        "**XGBoost** fue utilizado para entrenar un modelo de clasificación capaz de predecir si a un usuario le gustará un libro.\n",
        "\n",
        "Mediante **feature engineerering**, incorporamos información relevante sobre usuarios y libros, mejorando la capacidad predictiva del modelo.\n",
        "\n",
        "Las recomendaciones generadas ofrecen una diversidad global significativa, lo cual es beneficioso para mantener el interés del usuario y promover una exploración más amplia del catálogo.\n",
        "\n",
        "Este enfoque demuestra cómo la integración de diferentes técnicas puede conducir a soluciones efectivas en el desarrollo de sistemas de recomendación personalizados.\n",
        "\n"
      ],
      "metadata": {
        "id": "SyEci76dolpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Gracias por completar este laboratorio!"
      ],
      "metadata": {
        "id": "Pd7014q0o2E_"
      }
    }
  ]
}